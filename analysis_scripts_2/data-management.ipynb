{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aff26ae7",
   "metadata": {},
   "source": [
    "# TMS Data Management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7eb6ab7",
   "metadata": {},
   "source": [
    "This script reads in raw data from participant sessions (i.e. output from the `PsychoPy` test instrument software). It reformats it into a single `.csv` file containing item-level information for all participants and sessions. Here, \"item-level\" means that each observation (row in the dataset) represents one person's observation of (response to) one stimulus prompt (question), necessarily under one TMS condition (brain region).\n",
    "\n",
    "Before running this code, follow the **Setup instructions** below to ensure that raw data is present and discoverable. Also, pay attention to the **Options**: some aspects of this script, such as whether to randomly anonymize treatment conditions and/or content domains (types of questions), are configurable. The options also specify the names of the input and output files.\n",
    "\n",
    "The output directory is called `processed-data-[x]` in the working directory, where `x` is the (configurable) version number. If anonymization is used, the masking scheme is given in `processed-data-[x]/secret-keys`. The actual dataframe is the `tms-functional-data-v[x].csv` file in the output directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c20ae5a",
   "metadata": {},
   "source": [
    "## Setup instructions: getting data into the filesystem\n",
    "- From Google Drive, download the [_functional\\_data_](https://drive.google.com/drive/folders/1NCyoM-Uj-h0-F7_a6ywdBssdFzRjxvYG) folder. This will automatically zip the contents.\n",
    "- Put the above two files into your working directory and `unzip` the first one.\n",
    "- Rename the new directory from `functional_data` to `test-data-[x]`, e.g. I'm using `test-data-1`.\n",
    "- In the cell below (under __Options__), redefine the `input_version` variable to whatever you chose `x` to be (so mine is set to 1). Also pick an output version number and set the variable `output_version` accordingly (I chose 1).\n",
    "- Participant 00001 has two copies of one of the `.csv` files. One is corrupted, so we rename it accordingly:\n",
    "```\n",
    "$ cd test-data-[x]/00001\n",
    "$ mv 00001_codetms_version2_2023-04-04_11h35.48.881block_1.csv 00001_codetms_version2_2023-04-04_11h35.48.881block_1-corrupted.csv\n",
    "```\n",
    "- Download the [Logistics](https://docs.google.com/spreadsheets/d/1_iH6ziOTDaZRM1K2_0EuHF3drL8ncgBdipbqAYnCkEs/edit#gid=0) sheet into your new `test-data-[x]` directory. Rename it to `logistics.csv`\n",
    "- Download the [post survey results](https://docs.google.com/spreadsheets/d/1QSpX9H8o5w8oLm6xEd_R7H0eWunDcEqh2Mt9uwmGUhw/edit?usp=sharing) sheet into your new `test-data-[x]` directory. Rename it to `post_survey_results.csv`\n",
    "- Now you should be good to go!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cdab6b",
   "metadata": {},
   "source": [
    "## Options (you can change these)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8842d823",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = False # whether to print verbose debugging output (set to False if using anonymization)\n",
    "\n",
    "input_version = 1 # input test data version\n",
    "output_version = 3 # output version (for distinguish different anonymizations, etc.)\n",
    "\n",
    "output = False # whether to output the results to a file\n",
    "\n",
    "reset_indices = True # whether to change the ranges of stimulus indices to be contiguous (original indices are still retained)\n",
    "\n",
    "mask_flags = {\"treatment_condition\" : True, # whether to anonymize the treatment condition (vertex, sma, m1)\n",
    "              \"stimulus_domain\" : True, # whether to anonymize the stimulus domain (list/array, tree, shepard-metzler, PSVT:R II, code)\n",
    "             }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add35624",
   "metadata": {},
   "source": [
    "## Miscellaneous code setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6752e27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0888080",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadirname = \"test-data-%d\" % input_version # the name of the directory where all the data is stored\n",
    "\n",
    "# values needed to calculate random mask for anonymization\n",
    "mask_vals = {\"treatment_condition\" : [\"sma\", \"m1\", \"vertex\"],\n",
    "             \"stimulus_domain\" : [\"list/array\", \"tree\", \"shepard-metzler\", \"PSVT:R II\", \"code\"]}\n",
    "\n",
    "# starting points of the mask output ranges\n",
    "mask_start = {\"treatment_condition\" : 'X',\n",
    "              \"stimulus_domain\" : 'A'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43350989",
   "metadata": {},
   "source": [
    "## Gather raw data from filesystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2840595c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary mapping participant id to set of corresponding filenames\n",
    "data_files = {}\n",
    "\n",
    "# find all the csv files, grouped by participant\n",
    "for root, dirs, files in os.walk(datadirname):\n",
    "    for fname in files:\n",
    "        # for each participant and session, the data is stored in several\n",
    "        # different file formats; we just pick one and stay consistent\n",
    "        if fname[-11:] == \"block_1.csv\":\n",
    "            id = str(fname[:5])\n",
    "            fullname = os.path.join(root, fname)\n",
    "            if id in data_files.keys():\n",
    "                data_files[id].add(fullname)\n",
    "            else:\n",
    "                data_files[id] = {fullname}\n",
    "\n",
    "# remove any participants without enough data; two sessions is ok but\n",
    "# we can't do anything if there's just one (not applicable for final data)\n",
    "data_files = {id : fileset for id, fileset in data_files.items() if len(fileset) >= 2}\n",
    "\n",
    "# print things out just to check\n",
    "if verbose:\n",
    "    for (id, fileset) in data_files.items():\n",
    "        print(id, \":\")\n",
    "        for file in fileset:\n",
    "            print(\"\\t\", file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ce0669a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dictionary mapping participant to list of session types in chronological order\n",
    "\n",
    "sessionsdf = pd.read_csv(datadirname + \"/logistics.csv\")\n",
    "\n",
    "# all metadata for the participant\n",
    "sessions = {id : sessionsdf.loc[sessionsdf[\"Participant_ID\"] == int(id)]\n",
    "            for id in data_files.keys()}\n",
    "\n",
    "# only keep session type data\n",
    "sessions = {id : \n",
    "            [sessions[id].reset_index()._get_value(0, (\"Session Type %d\" % k))\n",
    "             for k in range(1, len(fnames) + 1)]\n",
    "            for id, fnames in data_files.items()}\n",
    "\n",
    "# split experimental condition and test version\n",
    "sessions = {id : [info.split(\", version \") for info in sessions[id]]\n",
    "            for id in sessions.keys()}\n",
    "\n",
    "# store as a dict of dicts rather than lists\n",
    "sessions = {id : [{\"condition\" : ls[0], \"version\" : int(ls[1])} for ls in ls]\n",
    "            for id, ls in list(sessions.items())}\n",
    "\n",
    "if verbose:\n",
    "    display(sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc762552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# given the session info and fileset for a participant, combine and store everything we need\n",
    "def categorize(id, infolist, fileset):\n",
    "    dict = {}\n",
    "    \n",
    "    # for each session\n",
    "    for i, info in enumerate(infolist):\n",
    "        v = info[\"version\"]\n",
    "        \n",
    "        # find the filename\n",
    "        matching_fnames = [fname for fname in fileset if fname.find(\"version%d\" % v) >= 0]\n",
    "        fname = None\n",
    "        if len(matching_fnames) != 1:\n",
    "            print(\"ERROR: unexpected number of files for participant %s, test version $s\" % (id, v))\n",
    "            print(\"       expected 1, found %d\" % len(matching_fnames))\n",
    "            print(\"      \", matching_fnames)\n",
    "        else:\n",
    "            fname = matching_fnames[0]\n",
    "        \n",
    "        # map experiment condition to its (0-indexed) chronological session number, version \n",
    "        # of the test administered, and name of the .csv file containing the data\n",
    "        dict[info[\"condition\"]] = {\"session_num\" : i,\n",
    "                                \"test_version\" : v,\n",
    "                                \"file_name\" : fname}\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb2aeabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store all the current relevant participant info into one dictionary\n",
    "metadata = {id : categorize(id, infolist, data_files[id]) for id, infolist in sessions.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "088b4319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the result to check\n",
    "if verbose:\n",
    "    for id, data in metadata.items():\n",
    "        print(\"participant\", id, \":\")\n",
    "        for condition, sessiondata in data.items():\n",
    "            print(\"   \", condition, \":\")\n",
    "            for k, v in sessiondata.items():\n",
    "                print(\"      \", k, \":\", v)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba5bfe5",
   "metadata": {},
   "source": [
    "The cell below categorizes our stimuli by index into their respective content domains (topics). This can be cross-referenced with our stimuli, which are provided in the replication package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22aff4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# given a stimulus number, return the category of the question\n",
    "\n",
    "# note that we're separating the two positive control categories \"shepard-metzler\"\n",
    "# and \"PSVT:R II\" - see the per-category average scores in the next section for why\n",
    "def categorize_stimulus(n, print_errors=True):\n",
    "    if n in [0, 8, 12, 21, 26, 28, 30, 36, 44, 50, 58, 61, 62, 78, 79]:\n",
    "        if verbose and print_errors:\n",
    "            print(\"ERROR: {} not a valid stimulus number\".format(n))\n",
    "        return \"ERROR\" # ERROR! we have no such stimuli\n",
    "    \n",
    "    elif n < 31:\n",
    "        return \"list/array\" # inserting to or bubble sorting linked lists or arrays\n",
    "    elif n < 61:\n",
    "        return \"tree\" # rotating or traversing a binary tree\n",
    "    elif n < 91:\n",
    "        return \"shepard-metzler\" # which block is the same as the prompt, but rotated?\n",
    "    elif n < 121:\n",
    "        return \"PSVT:R II\" # a is to a' as b is to which? (rotating blocks again)\n",
    "    elif n < 151:\n",
    "        return \"code\" # what is the output of this code snippet?\n",
    "    \n",
    "    elif n < 201:\n",
    "        if verbose and print_errors:\n",
    "            print(\"ERROR: {} not a valid stimulus number\".format(n))\n",
    "        return \"ERROR\" # ERROR! we have no such stimuli\n",
    "    \n",
    "    elif n < 208:\n",
    "        return \"list/array\" # again\n",
    "    elif n < 215:\n",
    "        return \"tree\" # again\n",
    "    \n",
    "    elif n < 301:\n",
    "        if verbose and print_errors:\n",
    "            print(\"ERROR: {} not a valid stimulus number\".format(n))\n",
    "        return \"ERROR\" # ERROR! we have no such stimuli\n",
    "    \n",
    "    elif n < 315:\n",
    "        return \"tree\" # again\n",
    "    elif n < 317:\n",
    "        return \"code\" # again\n",
    "    elif n < 324:\n",
    "        return \"tree\" # again\n",
    "    elif n < 327:\n",
    "        return \"code\" # again\n",
    "    elif n < 331:\n",
    "        return \"list/array\" # again\n",
    "    elif n < 334:\n",
    "        return \"code\"\n",
    "    \n",
    "    else:\n",
    "        if verbose and print_errors:\n",
    "            print(\"ERROR: {} not a valid stimulus number\".format(n))\n",
    "        return \"ERROR\" # ERROR! we have no such stimuli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40d7b64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# given the .csv filename for a session, read the necessary information into a dataframe\n",
    "def read_session_data(fname):\n",
    "    # columns to drop\n",
    "    drop_cols = [\"n\", \"stim_resp.corr_mean\", \"stim_resp.corr_raw\", \"stim_resp.corr_std\",\n",
    "                 \"stim_resp.rt_raw\", \"stim_resp.rt_std\"]\n",
    "\n",
    "    # what type to read the columns as\n",
    "    dtypes = {\"figure1\" : \"str\", \n",
    "              \"corrAns\" : \"str\", \n",
    "              \"stim_resp.keys_raw\" : \"str\", \n",
    "              \"stim_resp.rt_mean\" : \"float64\", \n",
    "              \"order\" : \"float64\"}\n",
    "\n",
    "    # what to name the columns as\n",
    "    rename = {\"figure1\" : \"stimulus\", # the number of this stimulus in the question bank\n",
    "              \"corrAns\" : \"correct_response\", # the correct answer (\"a\" or \"b\")\n",
    "              \"stim_resp.keys_raw\" : \"actual_response\", \n",
    "              \"stim_resp.rt_mean\" : \"response_time\", # in seconds (I think)\n",
    "              \"order\" : \"question_num\"}\n",
    "\n",
    "    # read in the data\n",
    "    df = pd.read_csv(fname, dtype=dtypes).drop(columns=drop_cols) #.dropna()\n",
    "    \n",
    "    # find the extra comments at the end and get rid of them\n",
    "    idx = df.index[df[\"figure1\"] == \"extraInfo\"].tolist()[0]\n",
    "    df = df.drop(index=range(idx, df.shape[0])).rename(columns=rename)\n",
    "    \n",
    "    # get the stimulus number and question type out of the file name\n",
    "    df[\"stimulus\"] = [int(s[:-4]) for s in df[\"stimulus\"]]\n",
    "    df[\"domain\"] = [categorize_stimulus(n) for n in df[\"stimulus\"]]\n",
    "    \n",
    "    # cast float to integer\n",
    "    #df[\"question_num\"] = [int(n) for n in df[\"question_num\"]]\n",
    "    \n",
    "    # sort rows in chonological order (i.e. the order they were presented to the participant)\n",
    "    df = df.sort_values(by=\"question_num\", axis=0).reset_index().drop(columns=[\"index\", \"question_num\"])\n",
    "\n",
    "    # condense the response value information\n",
    "    df[\"actual_response\"] = [s[1] for s in df[\"actual_response\"]]\n",
    "    df[\"correct\"] = df[\"actual_response\"] == df[\"correct_response\"]\n",
    "    #df = df.drop(columns=[\"correct_response\", \"actual_response\"])\n",
    "    \n",
    "    # return it\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90b75976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do an example for a single file\n",
    "testdf = read_session_data(\"test-data-{}/00782/00782_codetms_version3_2023-05-31_15h49.35.491block_1.csv\".format(input_version))\n",
    "\n",
    "# print it out to check\n",
    "if verbose:\n",
    "    print(\"shape:\", testdf.shape)\n",
    "    display(testdf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1938fb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now stick everything in a dataframe\n",
    "main_ds_dict = {}\n",
    "for id, data in metadata.items():\n",
    "    participant_ds_dict = {}\n",
    "    for condition, sessiondata in data.items():\n",
    "        df = read_session_data(sessiondata[\"file_name\"])\n",
    "        \n",
    "        df[\"session_num\"] = sessiondata[\"session_num\"]\n",
    "        df[\"test_version\"] = sessiondata[\"test_version\"]\n",
    "        \n",
    "        participant_ds_dict[condition] = df.stack()\n",
    "    main_ds_dict[id] = pd.concat(participant_ds_dict, axis=0)\n",
    "\n",
    "main_ds = pd.concat(main_ds_dict, axis=0)\n",
    "rename = {\"level_0\" : \"id\", \"level_1\" : \"condition\", \"level_2\" : \"question\"}\n",
    "main_df = main_ds.unstack().reset_index().rename(columns=rename)\n",
    "\n",
    "if verbose:\n",
    "    print(\"Main dataframe:\")\n",
    "    display(main_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "edaee2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check that the session number isn't always zero (as it looks from the output above)\n",
    "if verbose:\n",
    "    display(main_df.head(104))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0e5e7c",
   "metadata": {},
   "source": [
    "## Add the post-test survey results to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20d16caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataframe of the survey data we want to keep\n",
    "\n",
    "# read in the data, dropping any unnecessary information\n",
    "drop_cols = [\"date\", # PID\n",
    "             \"mr_difficulty_change\", \"programming_difficulty_change\", # to difficult to cross-reference\n",
    "             \"discomfort\", \"other_comments\", # not interesting for quantitative data analysis\n",
    "             \"transcriber_notes\", \"Unnamed: 12\", \"Unnamed: 13\"] # miscellaneous researcher notes\n",
    "\n",
    "dtypes = {\"participant_num\" : \"str\"}\n",
    "\n",
    "surveydf = pd.read_csv(datadirname + \"/post_survey_results.csv\", dtype=dtypes).drop(columns=drop_cols)\n",
    "\n",
    "rename = {\"participant_num\" : \"id\", \n",
    "          \"treatment\" : \"condition\", \n",
    "          \"session_no\" : \"session_num\", \n",
    "          \"questions_version\" : \"test_version\"}\n",
    "\n",
    "surveydf.rename(columns=rename, inplace=True)\n",
    "\n",
    "surveydf[\"session_num\"] = surveydf[\"session_num\"] - 1 # I zero-indexed this\n",
    "\n",
    "if verbose:\n",
    "    display(surveydf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0e411f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = main_df.merge(surveydf, on=[\"id\", \"condition\", \"session_num\", \"test_version\"], how=\"outer\", indicator=True)\n",
    "\n",
    "if verbose:\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0ae7464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we expect these to have the same number of rows, but `df` has 3 extra columns with information from the merge\n",
    "if verbose:\n",
    "    print(main_df.shape)\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81e5da73",
   "metadata": {},
   "outputs": [],
   "source": [
    "if verbose:\n",
    "    display(df[\"_merge\"].value_counts())    # left_only are observations we don't have survey data for\n",
    "                                            # right_only should habe 0 entries\n",
    "\n",
    "    # run this if you want to see them\n",
    "    display(df.loc[df[\"_merge\"] == \"left_only\"][\"id\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de7fdb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"_merge\"] = df[\"_merge\"] == \"both\"\n",
    "df.rename(columns = {\"_merge\" : \"has_survey\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d8c9a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e5a599",
   "metadata": {},
   "source": [
    "## Distinguish mental rotation questions from programming questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9cc2939a",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df[\"is_mr\"] = main_df[\"domain\"].isin([\"shepard-metzler\", \"PSVT:R II\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1ff338f",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df[\"is_programming\"] = main_df[\"is_mr\"] == False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ecd73bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if verbose:\n",
    "    display(main_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13039bbd",
   "metadata": {},
   "source": [
    "## Four of the stimuli had incorrectly-coded \"correct responses\" at the time of data collection, so we flip the values here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8451457a",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_correct_answers = {'a' : [], 'b' : [106, 118, 140, 332]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "debf1e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "if verbose:\n",
    "    for ans, ls in actual_correct_answers.items():\n",
    "        print(\"------- correct answer is {} -------\".format(ans))\n",
    "        for stimulus in ls:\n",
    "            correct_response = main_df[main_df[\"stimulus\"] == stimulus][\"correct_response\"].iloc[0]\n",
    "            print(\"Stimulus #{}: correct answer coded as {}\".format(stimulus, correct_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0aa1f009",
   "metadata": {},
   "outputs": [],
   "source": [
    "if verbose:\n",
    "    display(main_df[main_df[\"stimulus\"] == 106].head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "93e20aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ans, ls in actual_correct_answers.items():\n",
    "    for stimulus in ls:\n",
    "        ii = main_df[\"stimulus\"] == stimulus\n",
    "        main_df.loc[ii, \"correct_response\"] = ans\n",
    "\n",
    "main_df[\"correct\"] = main_df[\"correct_response\"] == main_df[\"actual_response\"] # have to regenerate this derived column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d8f85afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if verbose:\n",
    "    for c, ls in actual_correct_answers.items():\n",
    "        print(\"------- correct answer is {} -------\".format(c))\n",
    "        for stimulus in ls:\n",
    "            correct_response = main_df[main_df[\"stimulus\"] == stimulus][\"correct_response\"].iloc[0]\n",
    "            print(\"Stimulus #{}: correct answer coded as {}\".format(stimulus, correct_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "65bcba17",
   "metadata": {},
   "outputs": [],
   "source": [
    "if verbose:\n",
    "    display(main_df[main_df[\"stimulus\"] == 106].head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "beb5255c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if verbose:\n",
    "    display(main_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c689dbbf",
   "metadata": {},
   "source": [
    "## Anonymize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8836d61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate masks\n",
    "def mask(df, arr, start):\n",
    "    nums = random.sample(range(len(arr)), len(arr))\n",
    "    mask = {x : chr(ord(start) + nums[i]) for i, x in enumerate(arr)}\n",
    "    df.replace(to_replace=mask, inplace=True)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d3625138",
   "metadata": {},
   "outputs": [],
   "source": [
    "if verbose:\n",
    "    display(mask(pd.DataFrame([]), [1, 2, 3], 'Q')) # example random masking scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e11edca",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_keys = {}\n",
    "for k, v in mask_flags.items():\n",
    "    if v:\n",
    "        mask_keys[k] = mask(main_df, mask_vals[k], mask_start[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "406d2822",
   "metadata": {},
   "outputs": [],
   "source": [
    "if verbose:\n",
    "    display(mask_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebd638e",
   "metadata": {},
   "source": [
    "## Fill in gaps in the stimulus indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d1831e",
   "metadata": {},
   "source": [
    "Here, we re-index the stimuli in a new `adjusted_stimulus` column. This has no impact on the data analysis, as stimuli are treated categorically. Original stimulus indices are retained in the dataset as `original_stimulus`. The change is purely for aesthetics when data are visualized, so that stimuli of the same domain can be more easily compared. There is a minor additional benefit, in that original stimuli can \"give away\" the anonymization scheme to someone who knows the data well.\n",
    "\n",
    "The re-indexing results in stimuli numbered 1-183 in alphabetical order of the domain names. Within each domain, order of stimuli is preserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4335aaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell establishes our knowledge of the indices which don't have a corresponding stimulus\n",
    "# only the first block should have any indices printed\n",
    "if verbose:\n",
    "    # show the missing stimulus indices (there is a large section missing in the middle)\n",
    "    old_stimuli = pd.unique(main_df[\"stimulus\"])\n",
    "\n",
    "    print(\"indices missing from first block, range [1, 150]:\\n\\t\", end='')\n",
    "    for k in range(1, 151):\n",
    "        if not k in old_stimuli:\n",
    "            print(\"{}\".format(k), end=\",  \")\n",
    "\n",
    "    print(\"\\nindices missing from second block, range [201, 214]:\\n\\t\", end='')\n",
    "    for k in range(201, 215):\n",
    "        if not k in old_stimuli:\n",
    "            print(\"{}\".format(k), end=\",  \")\n",
    "\n",
    "    print(\"\\nindices missing from third block, range [301, 333]:\\n\\t\", end='')\n",
    "    for k in range(301, 333):\n",
    "        if not k in old_stimuli:\n",
    "            print(\"{}\".format(k), end=\",  \")\n",
    "\n",
    "    print(\"\\nindices present in between the first and second blocks, range [151, 200]:\\n\\t\", end='')\n",
    "    for k in range(151, 201):\n",
    "        if k in old_stimuli:\n",
    "            print(\"{}\".format(k), end=\",  \")\n",
    "\n",
    "    print(\"\\nindices present in between the second and third blocks, range [215, 300]:\\n\\t\", end='')\n",
    "    for k in range(215, 300):\n",
    "        if k in old_stimuli:\n",
    "            print(\"{}\".format(k), end=\",  \")\n",
    "\n",
    "    #[k for k in range(1, 151) if k not in old_stimuli]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2b351591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift the ranges around\n",
    "# Note: I'm giving up on very general solutions here (which I tried to stick to above)\n",
    "# since part of the problem is the gaps in our specific set of stimuli.\n",
    "if reset_indices:\n",
    "    domains = pd.unique(main_df[\"domain\"])\n",
    "    \n",
    "    if not mask_flags[\"stimulus_domain\"]:\n",
    "        domains = mask_vals[\"stimulus_domain\"] # so the order doesn't get rearranged\n",
    "    \n",
    "    if verbose:\n",
    "        print(domains)\n",
    "    \n",
    "    new_idxs = {}\n",
    "    start = 1 # 1-indexing, unfortunately\n",
    "    \n",
    "    def idx_in_stimulus_domain(idx, dom):\n",
    "        cat = categorize_stimulus(idx, print_errors=False)\n",
    "        if cat == \"ERROR\":\n",
    "            return False\n",
    "        if not mask_flags[\"stimulus_domain\"]:\n",
    "            return cat == dom\n",
    "        return mask_keys[\"stimulus_domain\"][cat] == dom\n",
    "    \n",
    "    # the formatting here will look a little messed up if domains aren't anonymized\n",
    "    if verbose:\n",
    "        print(\"domain \\t old starting point \\t new starting point \\t count\")\n",
    "    \n",
    "    for dom in domains:\n",
    "        old_idxs = [k for k in range(1, max(main_df[\"stimulus\"])+1) if idx_in_stimulus_domain(k, dom)]\n",
    "        new_idxs |= {old_idx : (start + new_idx) for new_idx, old_idx in enumerate(old_idxs)}\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"{} \\t {} \\t\\t\\t {} \\t\\t\\t {}\".format(dom, old_idxs[0], new_idxs[old_idxs[0]], len(old_idxs)))\n",
    "        \n",
    "        start += len(old_idxs)\n",
    "    \n",
    "    if verbose and not start-1 == len(pd.unique(main_df[\"stimulus\"])):\n",
    "        print(\"ERROR there are {} unique stimuli, but {} have been stored\".format())\n",
    "    \n",
    "    main_df.rename(columns={\"stimulus\" : \"original_stimulus\"}, inplace=True)\n",
    "    \n",
    "    main_df[\"adjusted_stimulus\"] = main_df.apply(lambda row : new_idxs[row[\"original_stimulus\"]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7c71326a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if verbose:\n",
    "    display(main_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1478be",
   "metadata": {},
   "source": [
    "## Output the information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171b205c",
   "metadata": {},
   "source": [
    "Here, we write the fully-compiled dataframe to a `.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1cfcfcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "if verbose:\n",
    "    display(main_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f7c61961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the output directories\n",
    "if output:\n",
    "    path = os.path.realpath(\"__file__\")[:-len(\"__file__\")]\n",
    "\n",
    "    output_path = os.path.join(path, \"processed-data-{}\".format(output_version))\n",
    "    keys_path = os.path.join(output_path, \"secret_keys\")\n",
    "\n",
    "    output_fname = \"tms-functional-data-v{}.csv\".format(output_version)\n",
    "\n",
    "    try:\n",
    "        os.mkdir(output_path)\n",
    "        os.mkdir(keys_path)\n",
    "    except OSError as error:\n",
    "        if verbose:\n",
    "            print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "22b9df76",
   "metadata": {},
   "outputs": [],
   "source": [
    "if verbose and output:\n",
    "    print(path)\n",
    "    print(output_path)\n",
    "    print(keys_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "64921560",
   "metadata": {},
   "outputs": [],
   "source": [
    "if output:\n",
    "    main_df.to_csv(os.path.join(output_path, output_fname), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e7fe9231",
   "metadata": {},
   "outputs": [],
   "source": [
    "if output:\n",
    "    for k, v in mask_keys.items():\n",
    "        pd.DataFrame(v.items()).to_csv(os.path.join(keys_path, \"{}.csv\".format(k)), header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef5c362",
   "metadata": {},
   "source": [
    "## Read the data back in to see what it looks like"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ee659e",
   "metadata": {},
   "source": [
    "If you have not run this script with the current output version and with `output=True` at least once, then this cell will throw an exception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "44112d0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m input_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[43moutput_path\u001b[49m, output_fname), converters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[38;5;28mstr\u001b[39m})\n\u001b[1;32m      3\u001b[0m display(input_df\u001b[38;5;241m.\u001b[39mhead())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'output_path' is not defined"
     ]
    }
   ],
   "source": [
    "input_df = pd.read_csv(os.path.join(output_path, output_fname), converters={\"id\" : str})\n",
    "\n",
    "display(input_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3576cb0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
